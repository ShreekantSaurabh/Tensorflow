{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise\n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = housing.drop(['medianHouseValue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_val,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35294118, 0.06968818, 0.11716325, 0.04876939, 0.11544154,\n",
       "        0.14250838],\n",
       "       [0.60784314, 0.01124167, 0.01567349, 0.00836747, 0.01414241,\n",
       "        0.04502697],\n",
       "       [0.66666667, 0.02523017, 0.03134699, 0.02097119, 0.03025818,\n",
       "        0.21286603],\n",
       "       ...,\n",
       "       [0.09803922, 0.08962816, 0.08659218, 0.0481392 , 0.08057885,\n",
       "        0.38940153],\n",
       "       [0.68627451, 0.02110992, 0.03258845, 0.0189756 , 0.03453379,\n",
       "        0.19181804],\n",
       "       [0.43137255, 0.08538074, 0.11235258, 0.0650842 , 0.10689031,\n",
       "        0.14979104]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.037025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.037027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.037023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.037021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.037022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "6761             -0.02   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "3010             -0.02   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "7812             -0.02   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "8480             -0.02   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "1051             -0.02   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "\n",
       "      medianIncome  \n",
       "6761     -0.037025  \n",
       "3010     -0.037027  \n",
       "7812     -0.037023  \n",
       "8480     -0.037021  \n",
       "1051     -0.037022  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Above I got only numpy array, instead I want it as a dataframe with all the column names as in housing.head()\n",
    "\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16086</th>\n",
       "      <td>-0.019728</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.035173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8816</th>\n",
       "      <td>-0.019721</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.033190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>-0.019646</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.036217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>-0.019872</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.035599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14491</th>\n",
       "      <td>-0.019834</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.033714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "16086         -0.019728   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "8816          -0.019721   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "7175          -0.019646   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "16714         -0.019872   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "14491         -0.019834   -0.000051      -0.000155   -0.000105   -0.000164   \n",
       "\n",
       "       medianIncome  \n",
       "16086     -0.035173  \n",
       "8816      -0.033190  \n",
       "7175      -0.036217  \n",
       "16714     -0.035599  \n",
       "14491     -0.033714  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be treated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,\n",
    "                                                 y=y_train ,\n",
    "                                                 batch_size=10,\n",
    "                                                 num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\SHREEK~1.SAU\\AppData\\Local\\Temp\\tmpu3dzhkux\n",
      "INFO:tensorflow:Using config: {'_task_id': 0, '_master': '', '_log_step_count_steps': 100, '_train_distribute': None, '_tf_random_seed': None, '_service': None, '_eval_distribute': None, '_protocol': None, '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_model_dir': 'C:\\\\Users\\\\SHREEK~1.SAU\\\\AppData\\\\Local\\\\Temp\\\\tmpu3dzhkux', '_device_fn': None, '_keep_checkpoint_max': 5, '_is_chief': True, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_evaluation_master': '', '_save_checkpoints_steps': None, '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_task_type': 'worker', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002AE5A5289B0>, '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shreekant.saurabh\\AppData\\Local\\Continuum\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\shreekant.saurabh\\AppData\\Local\\Continuum\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\shreekant.saurabh\\AppData\\Local\\Continuum\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\SHREEK~1.SAU\\AppData\\Local\\Temp\\tmpu3dzhkux\\model.ckpt.\n",
      "INFO:tensorflow:loss = 770487550000.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 312.275\n",
      "INFO:tensorflow:loss = 958135800000.0, step = 101 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.82\n",
      "INFO:tensorflow:loss = 767696800000.0, step = 201 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.398\n",
      "INFO:tensorflow:loss = 307239450000.0, step = 301 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.578\n",
      "INFO:tensorflow:loss = 509788850000.0, step = 401 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.1\n",
      "INFO:tensorflow:loss = 245196420000.0, step = 501 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.975\n",
      "INFO:tensorflow:loss = 381514580000.0, step = 601 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.183\n",
      "INFO:tensorflow:loss = 497707200000.0, step = 701 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.379\n",
      "INFO:tensorflow:loss = 516674550000.0, step = 801 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.878\n",
      "INFO:tensorflow:loss = 697665000000.0, step = 901 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.47\n",
      "INFO:tensorflow:loss = 414547940000.0, step = 1001 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.293\n",
      "INFO:tensorflow:loss = 395748570000.0, step = 1101 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.354\n",
      "INFO:tensorflow:loss = 504340350000.0, step = 1201 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.577\n",
      "INFO:tensorflow:loss = 246065740000.0, step = 1301 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.398\n",
      "INFO:tensorflow:loss = 257652400000.0, step = 1401 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.098\n",
      "INFO:tensorflow:loss = 341671280000.0, step = 1501 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.77\n",
      "INFO:tensorflow:loss = 105936340000.0, step = 1601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.091\n",
      "INFO:tensorflow:loss = 542492260000.0, step = 1701 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.944\n",
      "INFO:tensorflow:loss = 505480500000.0, step = 1801 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.848\n",
      "INFO:tensorflow:loss = 303889840000.0, step = 1901 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.457\n",
      "INFO:tensorflow:loss = 410149160000.0, step = 2001 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.05\n",
      "INFO:tensorflow:loss = 185396450000.0, step = 2101 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.215\n",
      "INFO:tensorflow:loss = 75824680000.0, step = 2201 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.336\n",
      "INFO:tensorflow:loss = 159434520000.0, step = 2301 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.648\n",
      "INFO:tensorflow:loss = 706941300000.0, step = 2401 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.165\n",
      "INFO:tensorflow:loss = 429724430000.0, step = 2501 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.093\n",
      "INFO:tensorflow:loss = 157679650000.0, step = 2601 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.575\n",
      "INFO:tensorflow:loss = 60742885000.0, step = 2701 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.525\n",
      "INFO:tensorflow:loss = 222514220000.0, step = 2801 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.89\n",
      "INFO:tensorflow:loss = 264282080000.0, step = 2901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.984\n",
      "INFO:tensorflow:loss = 524406260000.0, step = 3001 (0.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 365.365\n",
      "INFO:tensorflow:loss = 106703050000.0, step = 3101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.588\n",
      "INFO:tensorflow:loss = 43594957000.0, step = 3201 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.737\n",
      "INFO:tensorflow:loss = 78092440000.0, step = 3301 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.825\n",
      "INFO:tensorflow:loss = 227774820000.0, step = 3401 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.695\n",
      "INFO:tensorflow:loss = 315547520000.0, step = 3501 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.868\n",
      "INFO:tensorflow:loss = 123999620000.0, step = 3601 (0.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 337.589\n",
      "INFO:tensorflow:loss = 98242200000.0, step = 3701 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.351\n",
      "INFO:tensorflow:loss = 109821936000.0, step = 3801 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.728\n",
      "INFO:tensorflow:loss = 34173710000.0, step = 3901 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.772\n",
      "INFO:tensorflow:loss = 43386585000.0, step = 4001 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.825\n",
      "INFO:tensorflow:loss = 60101878000.0, step = 4101 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.18\n",
      "INFO:tensorflow:loss = 207402420000.0, step = 4201 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.275\n",
      "INFO:tensorflow:loss = 449612870000.0, step = 4301 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.751\n",
      "INFO:tensorflow:loss = 270404880000.0, step = 4401 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.997\n",
      "INFO:tensorflow:loss = 82213230000.0, step = 4501 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.794\n",
      "INFO:tensorflow:loss = 67886690000.0, step = 4601 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.17\n",
      "INFO:tensorflow:loss = 234778600000.0, step = 4701 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.962\n",
      "INFO:tensorflow:loss = 106031040000.0, step = 4801 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.518\n",
      "INFO:tensorflow:loss = 142401340000.0, step = 4901 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.819\n",
      "INFO:tensorflow:loss = 32400175000.0, step = 5001 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.884\n",
      "INFO:tensorflow:loss = 143424980000.0, step = 5101 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.207\n",
      "INFO:tensorflow:loss = 389410060000.0, step = 5201 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.647\n",
      "INFO:tensorflow:loss = 48256946000.0, step = 5301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.18\n",
      "INFO:tensorflow:loss = 23831095000.0, step = 5401 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.114\n",
      "INFO:tensorflow:loss = 226103890000.0, step = 5501 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.942\n",
      "INFO:tensorflow:loss = 113585940000.0, step = 5601 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.207\n",
      "INFO:tensorflow:loss = 62132370000.0, step = 5701 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.327\n",
      "INFO:tensorflow:loss = 174931310000.0, step = 5801 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.538\n",
      "INFO:tensorflow:loss = 56339767000.0, step = 5901 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.339\n",
      "INFO:tensorflow:loss = 69583950000.0, step = 6001 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.713\n",
      "INFO:tensorflow:loss = 174708230000.0, step = 6101 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.675\n",
      "INFO:tensorflow:loss = 288595840000.0, step = 6201 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.028\n",
      "INFO:tensorflow:loss = 48648643000.0, step = 6301 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.272\n",
      "INFO:tensorflow:loss = 144018930000.0, step = 6401 (0.317 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 254.593\n",
      "INFO:tensorflow:loss = 312271140000.0, step = 6501 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.986\n",
      "INFO:tensorflow:loss = 59445590000.0, step = 6601 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.614\n",
      "INFO:tensorflow:loss = 250177130000.0, step = 6701 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.034\n",
      "INFO:tensorflow:loss = 84584620000.0, step = 6801 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.381\n",
      "INFO:tensorflow:loss = 65755640000.0, step = 6901 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.374\n",
      "INFO:tensorflow:loss = 74617635000.0, step = 7001 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.403\n",
      "INFO:tensorflow:loss = 82719425000.0, step = 7101 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 368.058\n",
      "INFO:tensorflow:loss = 242140700000.0, step = 7201 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.89\n",
      "INFO:tensorflow:loss = 183108730000.0, step = 7301 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.805\n",
      "INFO:tensorflow:loss = 135683670000.0, step = 7401 (0.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.206\n",
      "INFO:tensorflow:loss = 187402450000.0, step = 7501 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.835\n",
      "INFO:tensorflow:loss = 148679280000.0, step = 7601 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.173\n",
      "INFO:tensorflow:loss = 140017250000.0, step = 7701 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.78\n",
      "INFO:tensorflow:loss = 87743310000.0, step = 7801 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.804\n",
      "INFO:tensorflow:loss = 115837960000.0, step = 7901 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.311\n",
      "INFO:tensorflow:loss = 279095180000.0, step = 8001 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.753\n",
      "INFO:tensorflow:loss = 186383520000.0, step = 8101 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.402\n",
      "INFO:tensorflow:loss = 322734520000.0, step = 8201 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.329\n",
      "INFO:tensorflow:loss = 211446450000.0, step = 8301 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.169\n",
      "INFO:tensorflow:loss = 115183510000.0, step = 8401 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.933\n",
      "INFO:tensorflow:loss = 160302660000.0, step = 8501 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.169\n",
      "INFO:tensorflow:loss = 203502490000.0, step = 8601 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.574\n",
      "INFO:tensorflow:loss = 201341860000.0, step = 8701 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.768\n",
      "INFO:tensorflow:loss = 77456000000.0, step = 8801 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.393\n",
      "INFO:tensorflow:loss = 181329230000.0, step = 8901 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.218\n",
      "INFO:tensorflow:loss = 58153490000.0, step = 9001 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.382\n",
      "INFO:tensorflow:loss = 81792100000.0, step = 9101 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.771\n",
      "INFO:tensorflow:loss = 76296176000.0, step = 9201 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.308\n",
      "INFO:tensorflow:loss = 169003270000.0, step = 9301 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.338\n",
      "INFO:tensorflow:loss = 147967160000.0, step = 9401 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.806\n",
      "INFO:tensorflow:loss = 132101130000.0, step = 9501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.921\n",
      "INFO:tensorflow:loss = 178135900000.0, step = 9601 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.309\n",
      "INFO:tensorflow:loss = 157238000000.0, step = 9701 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.211\n",
      "INFO:tensorflow:loss = 209175280000.0, step = 9801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.435\n",
      "INFO:tensorflow:loss = 88418520000.0, step = 9901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.533\n",
      "INFO:tensorflow:loss = 179385810000.0, step = 10001 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.895\n",
      "INFO:tensorflow:loss = 106512490000.0, step = 10101 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.961\n",
      "INFO:tensorflow:loss = 132922710000.0, step = 10201 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.876\n",
      "INFO:tensorflow:loss = 123466370000.0, step = 10301 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.008\n",
      "INFO:tensorflow:loss = 168308460000.0, step = 10401 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.39\n",
      "INFO:tensorflow:loss = 92252730000.0, step = 10501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.857\n",
      "INFO:tensorflow:loss = 107253740000.0, step = 10601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.644\n",
      "INFO:tensorflow:loss = 264638480000.0, step = 10701 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.307\n",
      "INFO:tensorflow:loss = 190320920000.0, step = 10801 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.46\n",
      "INFO:tensorflow:loss = 93695740000.0, step = 10901 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 395.647\n",
      "INFO:tensorflow:loss = 304992400000.0, step = 11001 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.923\n",
      "INFO:tensorflow:loss = 160254210000.0, step = 11101 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.711\n",
      "INFO:tensorflow:loss = 72701180000.0, step = 11201 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.611\n",
      "INFO:tensorflow:loss = 111085700000.0, step = 11301 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.715\n",
      "INFO:tensorflow:loss = 115208405000.0, step = 11401 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.599\n",
      "INFO:tensorflow:loss = 250662200000.0, step = 11501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.943\n",
      "INFO:tensorflow:loss = 130657000000.0, step = 11601 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.553\n",
      "INFO:tensorflow:loss = 174953970000.0, step = 11701 (0.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.997\n",
      "INFO:tensorflow:loss = 152786470000.0, step = 11801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.713\n",
      "INFO:tensorflow:loss = 169994420000.0, step = 11901 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.105\n",
      "INFO:tensorflow:loss = 55179000000.0, step = 12001 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.584\n",
      "INFO:tensorflow:loss = 145326240000.0, step = 12101 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.438\n",
      "INFO:tensorflow:loss = 65626477000.0, step = 12201 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 366.351\n",
      "INFO:tensorflow:loss = 76800140000.0, step = 12301 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.599\n",
      "INFO:tensorflow:loss = 157291950000.0, step = 12401 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.009\n",
      "INFO:tensorflow:loss = 139887850000.0, step = 12501 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.072\n",
      "INFO:tensorflow:loss = 77077815000.0, step = 12601 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.964\n",
      "INFO:tensorflow:loss = 97148410000.0, step = 12701 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.667\n",
      "INFO:tensorflow:loss = 69279500000.0, step = 12801 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.981\n",
      "INFO:tensorflow:loss = 120461030000.0, step = 12901 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.806\n",
      "INFO:tensorflow:loss = 114171700000.0, step = 13001 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.407\n",
      "INFO:tensorflow:loss = 215745000000.0, step = 13101 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.008\n",
      "INFO:tensorflow:loss = 158549800000.0, step = 13201 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.791\n",
      "INFO:tensorflow:loss = 171242730000.0, step = 13301 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.155\n",
      "INFO:tensorflow:loss = 83266670000.0, step = 13401 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.316\n",
      "INFO:tensorflow:loss = 226992770000.0, step = 13501 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.488\n",
      "INFO:tensorflow:loss = 238866760000.0, step = 13601 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.021\n",
      "INFO:tensorflow:loss = 213196500000.0, step = 13701 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.183\n",
      "INFO:tensorflow:loss = 344442080000.0, step = 13801 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.837\n",
      "INFO:tensorflow:loss = 182780130000.0, step = 13901 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.594\n",
      "INFO:tensorflow:loss = 93293720000.0, step = 14001 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.677\n",
      "INFO:tensorflow:loss = 178813000000.0, step = 14101 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 379.458\n",
      "INFO:tensorflow:loss = 133943030000.0, step = 14201 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.983\n",
      "INFO:tensorflow:loss = 87915086000.0, step = 14301 (0.285 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 376.58\n",
      "INFO:tensorflow:loss = 243918670000.0, step = 14401 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.214\n",
      "INFO:tensorflow:loss = 35766810000.0, step = 14501 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.554\n",
      "INFO:tensorflow:loss = 39363633000.0, step = 14601 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.091\n",
      "INFO:tensorflow:loss = 134438530000.0, step = 14701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.218\n",
      "INFO:tensorflow:loss = 66247820000.0, step = 14801 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.905\n",
      "INFO:tensorflow:loss = 71826030000.0, step = 14901 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.262\n",
      "INFO:tensorflow:loss = 49280676000.0, step = 15001 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.57\n",
      "INFO:tensorflow:loss = 96097450000.0, step = 15101 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.43\n",
      "INFO:tensorflow:loss = 75290070000.0, step = 15201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.358\n",
      "INFO:tensorflow:loss = 271400580000.0, step = 15301 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.405\n",
      "INFO:tensorflow:loss = 215387700000.0, step = 15401 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.638\n",
      "INFO:tensorflow:loss = 54636945000.0, step = 15501 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.943\n",
      "INFO:tensorflow:loss = 139035920000.0, step = 15601 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.94\n",
      "INFO:tensorflow:loss = 263933950000.0, step = 15701 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.395\n",
      "INFO:tensorflow:loss = 131233730000.0, step = 15801 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.408\n",
      "INFO:tensorflow:loss = 47584985000.0, step = 15901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.732\n",
      "INFO:tensorflow:loss = 29430850000.0, step = 16001 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.544\n",
      "INFO:tensorflow:loss = 73463775000.0, step = 16101 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.822\n",
      "INFO:tensorflow:loss = 175689860000.0, step = 16201 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.711\n",
      "INFO:tensorflow:loss = 165523060000.0, step = 16301 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.799\n",
      "INFO:tensorflow:loss = 188436200000.0, step = 16401 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.698\n",
      "INFO:tensorflow:loss = 88406130000.0, step = 16501 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.38\n",
      "INFO:tensorflow:loss = 93219910000.0, step = 16601 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.591\n",
      "INFO:tensorflow:loss = 78929200000.0, step = 16701 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.084\n",
      "INFO:tensorflow:loss = 144019520000.0, step = 16801 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.043\n",
      "INFO:tensorflow:loss = 172753960000.0, step = 16901 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.097\n",
      "INFO:tensorflow:loss = 201468540000.0, step = 17001 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.759\n",
      "INFO:tensorflow:loss = 85060480000.0, step = 17101 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.667\n",
      "INFO:tensorflow:loss = 89883705000.0, step = 17201 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 349.784\n",
      "INFO:tensorflow:loss = 314856440000.0, step = 17301 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.347\n",
      "INFO:tensorflow:loss = 100224350000.0, step = 17401 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.764\n",
      "INFO:tensorflow:loss = 234640340000.0, step = 17501 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.976\n",
      "INFO:tensorflow:loss = 107907370000.0, step = 17601 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.683\n",
      "INFO:tensorflow:loss = 253274900000.0, step = 17701 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 367.687\n",
      "INFO:tensorflow:loss = 105670705000.0, step = 17801 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.463\n",
      "INFO:tensorflow:loss = 198673610000.0, step = 17901 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.525\n",
      "INFO:tensorflow:loss = 177037800000.0, step = 18001 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.603\n",
      "INFO:tensorflow:loss = 69318500000.0, step = 18101 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.635\n",
      "INFO:tensorflow:loss = 55837057000.0, step = 18201 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.507\n",
      "INFO:tensorflow:loss = 73205645000.0, step = 18301 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.972\n",
      "INFO:tensorflow:loss = 152355640000.0, step = 18401 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.659\n",
      "INFO:tensorflow:loss = 69222466000.0, step = 18501 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.165\n",
      "INFO:tensorflow:loss = 134364290000.0, step = 18601 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.344\n",
      "INFO:tensorflow:loss = 138210340000.0, step = 18701 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.77\n",
      "INFO:tensorflow:loss = 83871250000.0, step = 18801 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.299\n",
      "INFO:tensorflow:loss = 33786900000.0, step = 18901 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.576\n",
      "INFO:tensorflow:loss = 120982810000.0, step = 19001 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.201\n",
      "INFO:tensorflow:loss = 78038190000.0, step = 19101 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.098\n",
      "INFO:tensorflow:loss = 102821675000.0, step = 19201 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.336\n",
      "INFO:tensorflow:loss = 122845970000.0, step = 19301 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.604\n",
      "INFO:tensorflow:loss = 129273230000.0, step = 19401 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.732\n",
      "INFO:tensorflow:loss = 71334020000.0, step = 19501 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.425\n",
      "INFO:tensorflow:loss = 121029640000.0, step = 19601 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.397\n",
      "INFO:tensorflow:loss = 94523680000.0, step = 19701 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.653\n",
      "INFO:tensorflow:loss = 133764270000.0, step = 19801 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.993\n",
      "INFO:tensorflow:loss = 139776020000.0, step = 19901 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.811\n",
      "INFO:tensorflow:loss = 98490810000.0, step = 20001 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.371\n",
      "INFO:tensorflow:loss = 89221090000.0, step = 20101 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.256\n",
      "INFO:tensorflow:loss = 146005250000.0, step = 20201 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.846\n",
      "INFO:tensorflow:loss = 47531835000.0, step = 20301 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.066\n",
      "INFO:tensorflow:loss = 81500710000.0, step = 20401 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.327\n",
      "INFO:tensorflow:loss = 113968590000.0, step = 20501 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.928\n",
      "INFO:tensorflow:loss = 154372490000.0, step = 20601 (0.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.959\n",
      "INFO:tensorflow:loss = 93194020000.0, step = 20701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.307\n",
      "INFO:tensorflow:loss = 169927770000.0, step = 20801 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.647\n",
      "INFO:tensorflow:loss = 207831190000.0, step = 20901 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.455\n",
      "INFO:tensorflow:loss = 74459140000.0, step = 21001 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.341\n",
      "INFO:tensorflow:loss = 188451160000.0, step = 21101 (0.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.766\n",
      "INFO:tensorflow:loss = 79608410000.0, step = 21201 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.252\n",
      "INFO:tensorflow:loss = 109728660000.0, step = 21301 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.454\n",
      "INFO:tensorflow:loss = 69126750000.0, step = 21401 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.46\n",
      "INFO:tensorflow:loss = 188083680000.0, step = 21501 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.956\n",
      "INFO:tensorflow:loss = 41358836000.0, step = 21601 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.165\n",
      "INFO:tensorflow:loss = 261099700000.0, step = 21701 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.955\n",
      "INFO:tensorflow:loss = 68617142000.0, step = 21801 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.546\n",
      "INFO:tensorflow:loss = 248620730000.0, step = 21901 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.817\n",
      "INFO:tensorflow:loss = 235300400000.0, step = 22001 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 370.681\n",
      "INFO:tensorflow:loss = 127602870000.0, step = 22101 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.032\n",
      "INFO:tensorflow:loss = 176145300000.0, step = 22201 (0.301 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 341.023\n",
      "INFO:tensorflow:loss = 42940424000.0, step = 22301 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.775\n",
      "INFO:tensorflow:loss = 157527400000.0, step = 22401 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.899\n",
      "INFO:tensorflow:loss = 46447930000.0, step = 22501 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.51\n",
      "INFO:tensorflow:loss = 234940000000.0, step = 22601 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.974\n",
      "INFO:tensorflow:loss = 154521910000.0, step = 22701 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.072\n",
      "INFO:tensorflow:loss = 50747170000.0, step = 22801 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.011\n",
      "INFO:tensorflow:loss = 131951830000.0, step = 22901 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.338\n",
      "INFO:tensorflow:loss = 62029780000.0, step = 23001 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.975\n",
      "INFO:tensorflow:loss = 150226450000.0, step = 23101 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 377.392\n",
      "INFO:tensorflow:loss = 46251786000.0, step = 23201 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.291\n",
      "INFO:tensorflow:loss = 83854836000.0, step = 23301 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 360.454\n",
      "INFO:tensorflow:loss = 86237880000.0, step = 23401 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.304\n",
      "INFO:tensorflow:loss = 190007160000.0, step = 23501 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.78\n",
      "INFO:tensorflow:loss = 323043200000.0, step = 23601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.445\n",
      "INFO:tensorflow:loss = 34099810000.0, step = 23701 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.709\n",
      "INFO:tensorflow:loss = 63771390000.0, step = 23801 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 354.221\n",
      "INFO:tensorflow:loss = 100369555000.0, step = 23901 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.765\n",
      "INFO:tensorflow:loss = 67505830000.0, step = 24001 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.337\n",
      "INFO:tensorflow:loss = 151899650000.0, step = 24101 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.757\n",
      "INFO:tensorflow:loss = 145377020000.0, step = 24201 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.087\n",
      "INFO:tensorflow:loss = 348739400000.0, step = 24301 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.835\n",
      "INFO:tensorflow:loss = 74615340000.0, step = 24401 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.089\n",
      "INFO:tensorflow:loss = 75783720000.0, step = 24501 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.47\n",
      "INFO:tensorflow:loss = 134351495000.0, step = 24601 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.226\n",
      "INFO:tensorflow:loss = 184033050000.0, step = 24701 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.493\n",
      "INFO:tensorflow:loss = 137059230000.0, step = 24801 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.67\n",
      "INFO:tensorflow:loss = 290935770000.0, step = 24901 (0.345 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into C:\\Users\\SHREEK~1.SAU\\AppData\\Local\\Temp\\tmpu3dzhkux\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 153762430000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x2ae5a5282b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\SHREEK~1.SAU\\AppData\\Local\\Temp\\tmpu3dzhkux\\model.ckpt-25000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116428.02845699129"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
